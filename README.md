# Pr√©diction de Classe

## Description
Ce projet vise √† pr√©dire une classe cible en utilisant des techniques d'apprentissage automatique. Il comprend le pr√©traitement des donn√©es, la s√©lection des variables, ainsi que des m√©thodes d'√©quilibrage des classes.

## Contenu du projet
- **Classe_prediction.ipynb** : Notebook Jupyter contenant l'analyse et l'entra√Ænement du mod√®le.
- **Donn√©es** : Les donn√©es utilis√©es pour l'entra√Ænement et le test du mod√®le.
- **README.md** : Ce fichier expliquant le projet.

## Pr√©requis
Avant d'ex√©cuter le notebook, assurez-vous d'avoir les biblioth√®ques suivantes install√©es :

```bash
pip install pandas numpy scikit-learn matplotlib seaborn
```

## Ex√©cution
1. Clonez le d√©p√¥t :

```bash
git clone https://github.com/votre-utilisateur/nom-du-repo.git
cd nom-du-repo
```

2. Ouvrez le notebook et ex√©cutez les cellules dans l'ordre.

## Principales m√©thodes utilis√©es
- **Encodage des variables qualitatives**
- **S√©lection des variables importantes**
- **Sur-√©chantillonnage pour √©quilibrer les classes**
- **Pr√©diction et √©valuation du mod√®le**

## Algorithmes utilis√©s
Les algorithmes test√©s dans ce projet sont :
- **R√©gression Logistique**
- **Random Forest**
- **Gradient Boosting**
- **KNN**
- **AdaBoost**
- **Bagging Classifier**

Les meilleurs algorithmes en termes de performance sont **Random Forest** et **Gradient Boosting**, offrant une bonne pr√©cision et un bon √©quilibre des classes.

## R√©sum√© du Travail R√©alis√©
### Pr√©traitement des Donn√©es
- S√©lection des variables les plus pertinentes pour l'analyse.
- Encodage des variables cat√©gorielles afin de les rendre exploitables par les algorithmes de Machine Learning.
- Gestion du d√©s√©quilibre des classes cibles : mise en place de techniques comme le sur√©chantillonnage ou le sous-√©chantillonnage pour √©quilibrer les classes avant l'entra√Ænement des mod√®les.

### Partition des Donn√©es
S√©paration du jeu de donn√©es en trois ensembles :
- **Entra√Ænement (60%)** : utilis√© pour ajuster les mod√®les.
- **Validation (20%)** : utilis√© pour optimiser les hyperparam√®tres et comparer les mod√®les.
- **Test (20%)** : utilis√© pour √©valuer la performance finale du meilleur mod√®le.

### Mod√©lisation & Optimisation
- Exp√©rimentation avec six algorithmes de classification.
- Optimisation des hyperparam√®tres via une recherche par validation crois√©e (5-fold Cross Validation).

### √âvaluation & S√©lection du Mod√®le
- Comparaison des performances des mod√®les sur l‚Äôensemble de validation.
- Classement des mod√®les en fonction de plusieurs m√©triques (Accuracy, Pr√©cision, Recall, F1-score).

### Validation Finale
- Test du meilleur mod√®le sur l‚Äôensemble de test afin d‚Äôobtenir une √©valuation objective et g√©n√©ralisable.

## Conclusion
L‚Äôapproche adopt√©e garantit une s√©lection rigoureuse du mod√®le optimal, en √©vitant le surapprentissage et en assurant une bonne g√©n√©ralisation sur de nouvelles donn√©es, tout en prenant en compte le d√©s√©quilibre des classes cibles pour am√©liorer les performances des mod√®les sur des jeux de donn√©es d√©s√©quilibr√©s. üöÄ

## Auteur
- Seif Bgra


